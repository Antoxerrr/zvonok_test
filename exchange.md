Для решения будем использовать асинхронную архитектуру с использованием очереди сообщений.

Будет 3 компонента:

- Сервис А (Производитель/Producer)
- Брокер (очередь сообщений)
- Сервис Б (Потребитель/Consumer)

Сервис А будет отправлять сообщения в очередь, где эти сообщения будут храниться, а сервис Б будет в своём темпе брать эти сообщения и обрабатывать.
В качестве брокера можно выбрать RabbitMQ, с нагрузкой в 200 000 запросов в час он должен справиться. Ещё можно выбрать Kafka, но к сожалению опыта работы с ним у меня нет :(

Принцип простой: Сервис А отправляет в очередь сообщение, где это сообщение хранится, а сервис Б будет "слушать" очередь и брать из неё сообщения в обработку.
В случае сбоя сервиса Б сообщения останутся в очереди, и будут ждать, пока сервис Б их оттуда достанет. В случае сбоя самой очереди (выключили свет, сервер с RabbitMQ упал),
сообщения будут утеряны. В этом случае мы можем выгружать их на диск, в RabbitMQ есть механизм "надежных" очередей и сообщений. Создадим durable очередь и persistent сообщения,
тогда и очередь и сообщения будут выгружаться на диск
